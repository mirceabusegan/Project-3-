


from datetime import datetime, timedelta
import requests
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import pandas as pd
import matplotlib.pyplot as plt
import nltk
import yfinance as yf





# Connecting to finviz.com to scrape the data on Stock News
#base URL
finviz_url = 'https://finviz.com/quote.ashx?t='
#List of stocks to be analyzed
tickers = ['AMZN', 'GOOG', 'AAPL', 'JPM', 'JNJ', 'XOM', 'F', 'DIS', 'CVX', 'UL']


#Pulling the data 
news_tables = {}
for ticker in tickers:
    #creating the URL for the request
    url = finviz_url + ticker
    #request
    response = requests.get(url=url, headers={'user-agent': 'my_app'})
    #parsing using BeautifulSoup
    html = BeautifulSoup(response.text, 'html')
    #looking for 'news-table' (the table on the webpage containing the news)
    #store the table with the news in the variable news_table
    news_table = html.find(id='news-table')
    #adds a key(stock ticker) and a value (the news table) to the news_table dictionary
    news_tables[ticker] = news_table
   
#Find the news title in every table row    
parsed_data = []

for ticker, news_table in news_tables.items():
      #find all the <tr> - table row containing the news title
      for row in news_table.findAll('tr'):
                       
             #Find <a> tag (containing title of the article)  and extract the title        
             title = row.find('a')
             if title:
               title = title.text 
             #if there is no title print "No article found"  
             else:
                print("No article link found.")
             #Extract the date and time from the <td> tag
             date_data=[]
             date_data =row.find('td').get_text(strip=True).split(' ')
            
                                    
             if len(date_data) == 1:
                time = date_data[0]
             else:
                if date_data[0] == 'Today': 
                    date = datetime.now().date()
                    time = date_data[1]
                else:
                    date = date_data[0]
                    time = date_data[1]
             #Add the ticker, title, date, and time to the the parsed_data list
             parsed_data.append([ticker, date, time, title])
# print (parsed_data)
# print(len(parsed_data))
      





#Creating a dataframe from the parsed_data list
df = pd.DataFrame(parsed_data, columns=['ticker', 'date', 'time', 'title'])
# CLEANING THE DATA *************************************************** 
#1. Deleting the rows that don't contain a title
df = df.dropna(subset=['title'])
#Normalizing the date format
df['date'] = pd.to_datetime(df['date']).dt.date
#create a file with the data to inspect it
df.to_csv('parsed_data.csv')
df.head(10)




#run the sentiment analysis on the titles 
vader = SentimentIntensityAnalyzer()
f = lambda title: vader.polarity_scores(title)['compound'] if title is not None else None
df['score'] = df['title'].apply(f)
df.to_csv('scores.csv')
df.head(10) 






#Filter the news going back maximum 7 days
week_news_df = df[df['date'] >= (datetime.now().date() - timedelta(days = 7))]

#calculate the average score for each day, and store it in a dataframe
mean_df = week_news_df.groupby(['ticker', 'date']).mean('score')
mean_df = mean_df.unstack()
mean_df = mean_df.xs('score', axis='columns').transpose()

#export to file
mean_df.to_csv('sentiment_scores.csv')
#print the dataframe
mean_df.head(20)


for ticker in tickers:
    if ticker in mean_df.columns:
        print(f"Renaming {ticker} to {ticker}_score")
        mean_df.rename(columns={ticker: ticker + '_score'}, inplace=True)
    else:
        print(f"{ticker} not found in DataFrame columns.")


# Plot a grouped bar graph for each 'Date'
tickers = mean_df.columns[1:]  # Exclude 'Date' column
bar_width = 0.1  # Width of the bars
x_positions = range(len(mean_df))  # The x-axis positions for each date

# For each ticker, plot bars at the correct positions
for i, ticker in enumerate(tickers):
    plt.bar(
        [x + i * bar_width for x in x_positions],  # Adjust x position for grouping
        mean_df[ticker],  # Values (sentiment scores)
        width=bar_width,  # Bar width
        label=ticker  # Label for legend
    )

# Add titles and labels
plt.title('Sentiment Scores of Different Tickers Over the Last 7 Days (Bar Plot)')
plt.xlabel('Date')
plt.ylabel('Average Sentiment Score')
plt.xticks([x + bar_width * (len(tickers) - 1) / 2 for x in x_positions], mean_df['Date'], rotation=45)

# Add legend
plt.legend(loc='upper left', bbox_to_anchor=(1,1))

# Adjust the layout and display the plot
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))  # Set the figure size (optional)

# Plot each ticker's scores over time
for ticker in mean_df.columns[1:]:  # Skip the 'Date' column (first column)
    plt.plot(mean_df['Date'], mean_df[ticker], label=ticker)

# Add titles and labels
plt.title('Sentiment Scores of Different Tickers Over the Last 7 Days')
plt.xlabel('Date')
plt.ylabel('Average Sentiment Score')
plt.xticks(rotation=45)  # Rotate x-axis labels for readability
plt.legend(loc='upper left', bbox_to_anchor=(1,1))

# Display the plot
plt.tight_layout()  # Adjust layout to avoid clipping
plt.show()

# plt.figure(figsize=(100, 50))
# mean_df.plot(kind='bar')
# plt.xlabel('Date')
# plt.ylabel('Average Sentiment score')
# plt.xticks(rotation=90)
# plt.legend(loc='upper left', bbox_to_anchor=(1,1))
# plt.tight_layout()
# plt.show()





# plt.figure(figsize=(100, 50))
# mean_df.plot(kind='bar')
# plt.xlabel('Date')
# plt.ylabel('Sentiment score')
# plt.xticks(rotation=45)
# plt.show()





start_date = mean_df.index.min()
end_date = mean_df.index.max()

start_date_str = start_date.strftime('%Y-%m-%d')
end_date_str = end_date.strftime('%Y-%m-%d')

# end_date = datetime.now()
# start_date = end_date - timedelta(days=7)


def fetch_data(tickers, start_date, end_date):
    data = yf.download(tickers, start=start_date, end=end_date)
    return data


def plot_data(data):
    fig, axes = plt.subplots(nrows=len(tickers), figsize=(10, 15))
    fig.suptitle('Stock Prices and Volumes Over the Last Week', fontsize=16)
    
    for i, ticker in enumerate(tickers):
        ax1 = axes[i]
        color1 = 'tab:blue'
        ax1.plot(data['Close'][ticker], label=f'{ticker} Price', color=color1)
        ax1.set_title(f'{ticker} Stock Price and Volume')
        ax1.set_xlabel('Date')
        ax1.set_ylabel('Adjusted Close Price', color=color1)
        ax1.tick_params(axis='y', labelcolor=color1)
        ax1.legend(loc='upper left')
        
        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
        color2 = 'tab:orange'
        ax2.plot(data['Volume'][ticker], label=f'{ticker} Volume', color=color2)
        ax2.set_ylabel('Volume', color=color2)
        ax2.tick_params(axis='y', labelcolor=color2)
        ax2.legend(loc='upper right')

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()



def main():
    stock_data = fetch_data(tickers, start_date, end_date)
    plot_data(stock_data)

if __name__ == '__main__':
    main()





start_date = mean_df.index.min()
end_date = mean_df.index.max()
print(f"Fetching data from {start_date} to {end_date}")


# Download stock price data
#stock_data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']
stock_data = yf.download(tickers, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))['Adj Close']


stock_data.index = stock_data.index.tz_localize(None)


mean_df.index = pd.to_datetime(mean_df.index)
stock_data.index = pd.to_datetime(stock_data.index)


# Merge and check columns
merged_df = pd.merge(mean_df, stock_data, left_index=True, right_index=True, how='inner')
print(merged_df.columns)  # This will let you see all column names



# fig, axes = plt.subplots(nrows=len(tickers), ncols=1, figsize=(10, 6 * len(tickers)))

# # Ensure 'axes' is always an array, even if there's only one subplot
# if len(tickers) == 1:
#     axes = [axes]

# for i, ticker in enumerate(tickers):
#     ax1 = axes[i]

#     # Plotting Scores
#     score_col = ticker + '_score'
#     if score_col in merged_df.columns:
#         ax1.plot(merged_df.index, merged_df[score_col], label=f'{ticker} Score', color='tab:red')
#     ax1.set_xlabel('Date')
#     ax1.set_ylabel('Score', color='tab:red')
#     ax1.tick_params(axis='y', labelcolor='tab:red')
    
#     # Create a second y-axis for stock prices
#     ax2 = ax1.twinx()
#     if ticker in merged_df.columns:
#         ax2.plot(merged_df.index, merged_df[ticker], label=f'{ticker} Price', color='tab:blue')
#     ax2.set_ylabel('Stock Price', color='tab:blue')
#     ax2.tick_params(axis='y', labelcolor='tab:blue')
    
#     # Title and layout
#     ax1.set_title(f'{ticker} Score vs Price')
#     ax1.legend(loc='upper left')
#     ax2.legend(loc='upper right')

# fig.tight_layout()
#plt.show()




# Creating subplots
fig, axes = plt.subplots(nrows=len(tickers), ncols=1, figsize=(10, 6 * len(tickers)))

# Ensure 'axes' is always an array, even if there's only one subplot
if len(tickers) == 1:
    axes = [axes]

for i, ticker in enumerate(tickers):
    ax1 = axes[i]

    # Plotting Scores
    score_col = ticker + '_score'
    if score_col in merged_df.columns and not merged_df[score_col].isna().all():
        ax1.plot(merged_df.index, merged_df[score_col], label=f'{ticker} Score', color='tab:red')
        ax1.legend(loc='upper left')

    ax1.set_xlabel('Date')
    ax1.set_ylabel('Score', color='tab:red')
    ax1.tick_params(axis='y', labelcolor='tab:red')
    
    # Create a second y-axis for stock prices
    ax2 = ax1.twinx()
    if ticker in merged_df.columns and not merged_df[ticker].isna().all():
        ax2.plot(merged_df.index, merged_df[ticker], label=f'{ticker} Price', color='tab:blue')
        ax2.legend(loc='upper right')

    ax2.set_ylabel('Stock Price', color='tab:blue')
    ax2.tick_params(axis='y', labelcolor='tab:blue')
    
    # Title for each subplot
    ax1.set_title(f'{ticker} Score vs Price')

fig.tight_layout()
plt.show()










