from datetime import datetime, timedelta
import requests
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import pandas as pd
import matplotlib.pyplot as plt
import nltk


# Connecting to finviz.com to scrape the data on Stock News
#base URL
finviz_url = 'https://finviz.com/quote.ashx?t='
#List of stocks to be analyzed
tickers = ['AMZN', 'GOOG', 'AAPL', 'JPM', 'JNJ', 'XOM', 'F', 'DIS', 'CVX', 'UL']


#Pulling the data 
news_tables = {}
for ticker in tickers:
    #creating the URL for the request
    url = finviz_url + ticker
    #request
    response = requests.get(url=url, headers={'user-agent': 'my_app'})
    #parsing using BeautifulSoup
    html = BeautifulSoup(response.text, 'html')
    #looking for 'news-table' (the table on the webpage containing the news)
    #store the table with the news in the variable news_table
    news_table = html.find(id='news-table')
    #adds a key(stock ticker) and a value (the news table) to the news_table dictionary
    news_tables[ticker] = news_table
   
#Find the news title in every table row    
parsed_data = []

for ticker, news_table in news_tables.items():
      #find all the <tr> - table row containing the news title
      for row in news_table.findAll('tr'):
                       
             #Find <a> tag (containing title of the article)  and extract the title        
             title = row.find('a')
             if title:
               title = title.text 
             #if there is no title print "No article found"  
             else:
                print("No article link found.")
             #Extract the date and time from the <td> tag
             date_data=[]
             date_data =row.find('td').get_text(strip=True).split(' ')
            
                                    
             if len(date_data) == 1:
                time = date_data[0]
             else:
                if date_data[0] == 'Today': 
                    date = datetime.now().date()
                    time = date_data[1]
                else:
                    date = date_data[0]
                    time = date_data[1]
             #Add the ticker, title, date, and time to the the parsed_data list
             parsed_data.append([ticker, date, time, title])
print (parsed_data)
print(len(parsed_data))
      


#Creating a dataframe from the parsed_data list
df = pd.DataFrame(parsed_data, columns=['Ticker', 'Date', 'Time', 'Title'])
#CLEANING THE DATA *************************************************** 
#1. Deleting the rows that don't contain a title
df = df.dropna(subset=['Title'])
#Normalizing the date format
df['Date'] = pd.to_datetime(df['Date']).dt.date
#create a file with the data to inspect it
df.to_csv('parsed_data.csv')
df.head(10)




#run the sentiment analysis on the titles 
vader = SentimentIntensityAnalyzer()
f = lambda title: vader.polarity_scores(title)['compound'] #if title is not None else None
df['Score'] = df['Title'].apply(f)
df.to_csv('scores.csv')
df.head(10)



#Filter the news going back maximum 7 days
week_news_df = df[df['Date'] >= (datetime.now().date() - timedelta(days = 7))]

#calculate the average score for each day, and store it in a dataframe
mean_df = week_news_df.groupby(['Ticker', 'Date']).mean('Score')
mean_df = mean_df.unstack()
mean_df = mean_df.xs('Score', axis='columns').transpose()
# Reset the index to make 'Date' a column
mean_df = mean_df.reset_index()
mean_df['Date'] = pd.to_datetime(mean_df['Date'])

# #export to file
mean_df.to_csv('sentiment_scores.csv')
#print the dataframe
mean_df.head(20)




for ticker in tickers:
    if ticker in mean_df.columns:
        print(f"Renaming {ticker} to {ticker}_score")
        mean_df.rename(columns={ticker: ticker + '_Score'}, inplace=True)
    else:
        print(f"{ticker} not found in DataFrame columns.")


# Plot a grouped bar graph for each 'Date'
tickers = mean_df.columns[1:]  # Exclude 'Date' column
bar_width = 0.1  # Width of the bars
x_positions = range(len(mean_df))  # The x-axis positions for each date

# For each ticker, plot bars at the correct positions
for i, ticker in enumerate(tickers):
    plt.bar(
        [x + i * bar_width for x in x_positions],  # Adjust x position for grouping
        mean_df[ticker],  # Values (sentiment scores)
        width=bar_width,  # Bar width
        label=ticker  # Label for legend
    )

# Add titles and labels
plt.title('Sentiment Scores of Different Tickers Over the Last 7 Days (Bar Plot)')
plt.xlabel('Date')
plt.ylabel('Average Sentiment Score')
plt.xticks([x + bar_width * (len(tickers) - 1) / 2 for x in x_positions], mean_df['Date'], rotation=45)

# Add legend
plt.legend(loc='upper left', bbox_to_anchor=(1,1))

# Adjust the layout and display the plot
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))  # Set the figure size (optional)

# Plot each ticker's scores over time
for ticker in mean_df.columns[1:]:  # Skip the 'Date' column (first column)
    plt.plot(mean_df['Date'], mean_df[ticker], label=ticker)

# Add titles and labels
plt.title('Sentiment Scores of Different Tickers Over the Last 7 Days')
plt.xlabel('Date')
plt.ylabel('Average Sentiment Score')
plt.xticks(rotation=45)  # Rotate x-axis labels for readability
plt.legend(loc='upper left', bbox_to_anchor=(1,1))

# Display the plot
plt.tight_layout()  # Adjust layout to avoid clipping
plt.show()

# plt.figure(figsize=(100, 50))
# mean_df.plot(kind='bar')
# plt.xlabel('Date')
# plt.ylabel('Average Sentiment score')
# plt.xticks(rotation=90)
# plt.legend(loc='upper left', bbox_to_anchor=(1,1))
# plt.tight_layout()
# plt.show()





import yfinance as yf
from datetime import datetime  # Import datetime

# Define the start and end date
start_date = datetime(2024, 10, 8)
end_date = datetime.now().date()  # Use current date as the end date

# Define the list of tickers
tickers = ['AMZN', 'GOOG', 'AAPL', 'JPM', 'JNJ', 'XOM', 'F', 'DIS', 'CVX', 'UL']

# Download historical data for all tickers
yf_data = yf.download(tickers, start=start_date, end=end_date)

# Print the downloaded data
print(yf_data)



# Get the Open, High, Low, Close and Volume Columns
stock_data = yf_data[['Open','High','Low', 'Close', 'Volume']]
stock_data.to_csv('stock_data.csv')
print(stock_data)



# Flatten the MultiIndex columns into simple column names
stock_data_reset = stock_data.copy()
stock_data_reset.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in stock_data_reset.columns.values]

# Clean up the column names
stock_data_reset.columns = [col.replace('_', '').replace(' ', '').replace('__', '_') for col in stock_data_reset.columns]

# Check the updated column names
print(stock_data_reset.columns)




stock_data_reset.to_csv('stocks.csv')





fig, axes = plt.subplots(nrows=len(tickers), figsize=(10, 15))
fig.suptitle('Stock Prices and Volumes Over the Last Week', fontsize=16)
    
for i, ticker in enumerate(tickers):
    ax1 = axes[i]
    color1 = 'tab:blue'
    ax1.plot(stock_data['Close'][ticker], label=f'{ticker} Price', color=color1)
    ax1.set_title(f'{ticker} Stock Price and Volume')
    ax1.set_xlabel('Date')
    ax1.set_ylabel('Adjusted Close Price', color=color1)
    ax1.tick_params(axis='y', labelcolor=color1)
    ax1.legend(loc='upper left')
        
    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
    color2 = 'tab:orange'
    ax2.plot(stock_data['Volume'][ticker], label=f'{ticker} Volume', color=color2)
    ax2.set_ylabel('Volume', color=color2)
    ax2.tick_params(axis='y', labelcolor=color2)
    ax2.legend(loc='upper right')

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()


# Concatenate DataFrames based on index
merged_df = pd.concat([stock_data_reset, mean_df], axis=1, join='outer')

# Check for duplicate columns and remove duplicates (if any)
if 'Date' in merged_df.columns:
    merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]

# Ensure the 'Date' column is in datetime format (if necessary)
merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce')

merged_df_cleaned = merged_df.copy()
# tickers = ['AMZN', 'GOOG', 'AAPL', 'JPM', 'JNJ', 'XOM', 'F', 'DIS', 'CVX', 'UL']

# # Create an empty list to hold the final column order
# final_order = ['Date']  # First column is always 'Date'

# # Loop through each ticker and group its columns together in the desired order
# for ticker in tickers:
#     # For each ticker, we need to group all of its columns together
#     ticker_columns = [
#         ticker,  # Add the ticker column itself (like 'AMZN', 'GOOG', etc.)
#         'Open' + ticker, 
#         'High' + ticker, 
#         'Low' + ticker, 
#         'Close' + ticker, 
#         'Volume' + ticker
#     ]
    
#     # Check if all the columns in the group exist in the DataFrame
#     existing_columns = [col for col in ticker_columns if col in merged_df_cleaned.columns]
    
#     # Debug print to check which columns are found
#     print(f"Ticker: {ticker}, Found columns: {existing_columns}")
    
#     # If at least the 'Date' column and ticker-related columns exist, add them to the final order
#     if len(existing_columns) > 1:  # Ensure there's more than just the 'Date' column
#         # Add the ticker's columns to the final column order
#         final_order.extend(existing_columns[1:])  # Add everything except the 'Date' column
#     else:
#         print(f"Columns for {ticker} not fully found. Missing: {set(ticker_columns) - set(existing_columns)}. Skipping...")

# # Reorder the DataFrame columns based on the final order list
# merged_df_cleaned = merged_df_cleaned[final_order]

# Debug print to check the new column order
print("Columns after reordering:", merged_df_cleaned.columns.tolist())



# Forward fill the NaT values in 'Date' column
merged_df_cleaned = merged_df.ffill()

# # Check the result
# print(merged_df_cleaned.head())

merged_df_cleaned.to_csv('Merged.csv')



print(merged_df_cleaned.head())

# Set 'Date' column as index (if not already set)
if 'Date' in merged_df_cleaned.columns:
    merged_df_cleaned.set_index('Date', inplace=True)

# Verify the index is now datetime
print(merged_df_cleaned.index)  # Should show DatetimeIndex
print(merged_df_cleaned.head())  # Check the first few rows to ensure dates are correct

# Creating subplots
fig, axes = plt.subplots(nrows=len(tickers), ncols=1, figsize=(10, 6 * len(tickers)))

# Ensure 'axes' is always an array, even if there's only one subplot
if len(tickers) == 1:
    axes = [axes]

# Loop through each ticker and plot
for i, ticker in enumerate(tickers):
    ax1 = axes[i]

    # Plotting Scores (left y-axis)
    score_col = ticker + '_Score'
    if score_col in merged_df_cleaned.columns and not merged_df_cleaned[score_col].isna().all():
        ax1.plot(merged_df_cleaned.index, merged_df_cleaned[score_col], label=f'{ticker} Score', color='tab:red')
        ax1.set_xlabel('Date')
        ax1.set_ylabel('Score', color='tab:red')
        ax1.tick_params(axis='y', labelcolor='tab:red')
        ax1.legend(loc='upper left')  # Place legend for score

    # Create a second y-axis for stock prices (right y-axis)
    ax2 = ax1.twinx()

    # Plotting Stock Prices (right y-axis)
    price_col = 'Close' + ticker
    if price_col in merged_df_cleaned.columns and not merged_df_cleaned[price_col].isna().all():
        ax2.plot(merged_df_cleaned.index, merged_df_cleaned[price_col], label=f'{ticker} Price', color='tab:blue')
        ax2.set_ylabel('Stock Price', color='tab:blue')
        ax2.tick_params(axis='y', labelcolor='tab:blue')
        ax2.legend(loc='upper right')  # Place legend for stock price

    # Setting title for each subplot
    ax1.set_title(f'{ticker} Score vs Price')

    # ** Format the x-axis to show actual dates **
    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())  # Automatically space out date ticks
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # Format date labels as Year-Month-Day

    # Optional: Rotate x-axis labels for better readability (if needed)
    for tick in ax1.get_xticklabels():
        tick.set_rotation(45)
    ax1.tick_params(axis='x', labelrotation=45)

# Automatically adjust layout to prevent overlap
fig.tight_layout()

# Show the plot
plt.show()







